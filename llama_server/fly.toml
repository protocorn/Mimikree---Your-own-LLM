# fly.toml app configuration file generated for llama-server on 2025-02-13T14:41:50-05:00
#
# See https://fly.io/docs/reference/configuration/ for information about how to use this file.
#

app = 'llama-server'
primary_region = 'iad'

[http_service]
  internal_port = 8080
  force_https = true
  auto_start_machines = true
  min_machines_running = 1
  processes = ['app']
  # Remove or set to false.
  auto_stop_machines = false

[[vm]]
  memory = '1gb'
  cpu_kind = 'shared'
  cpus = 1
