# fly.toml app configuration file generated for llama-server on 2025-07-03T13:41:15-04:00
#
# See https://fly.io/docs/reference/configuration/ for information about how to use this file.
#

app = 'llama-server'
primary_region = 'iad'

[build]

[http_service]
  internal_port = 8080
  force_https = true
  auto_stop_machines = 'stop'
  auto_start_machines = true
  min_machines_running = 1
  processes = ['app']

  [http_service.concurrency]
    type = 'connections'
    hard_limit = 500
    soft_limit = 300

[[vm]]
  memory = '4gb'
  cpu_kind = 'performance'
  cpus = 2
